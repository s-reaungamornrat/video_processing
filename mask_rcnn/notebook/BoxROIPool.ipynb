{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30ed111a-e4ac-4c68-9408-42afd69e6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "import numpy as np\n",
    "from torch.nn.modules.utils import _pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0fda41-e69a-4ec9-95ec-0cd47886d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.ops.poolers import LevelMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f98654-8465-4c73-a528-838864ace700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['out', 'proposals', 'image_shapes'])\n",
      "out  {'0': (torch.Size([2, 256, 200, 296]), False), '1': (torch.Size([2, 256, 100, 148]), False), '2': (torch.Size([2, 256, 50, 74]), False), '3': (torch.Size([2, 256, 25, 37]), False), 'pool': (torch.Size([2, 256, 13, 19]), False)}\n",
      "image_shapes  [(800, 861), (799, 1159)]\n",
      "proposals  [(torch.Size([801, 4]), 0.0, 861.0, False), (torch.Size([803, 4]), 0.0, 1159.0, False)]\n"
     ]
    }
   ],
   "source": [
    "data_dirpath='D:/data/mask_rcnn'\n",
    "data=torch.load(os.path.join(data_dirpath, 'box_roi_pool.pt'), map_location=torch.device(\"cpu\"),weights_only=True)\n",
    "print(data.keys())\n",
    "out=dict() # we need to remove gradient since we need to save memory\n",
    "for k, v in data['out'].items():\n",
    "    v.requires_grad=False\n",
    "    out[k]=v\n",
    "proposals=data['proposals']\n",
    "image_shapes=data['image_shapes']\n",
    "print('out ', {k:(v.shape, v.requires_grad) for k, v in out.items()})\n",
    "print('image_shapes ', image_shapes)\n",
    "print('proposals ', [(p.shape, p.min().item(), p.max().item(), p.requires_grad) for p in proposals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5f31bb4-7d1f-4409-9584-5872510d9c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _filter_input(x: dict[str, Tensor], featmap_names: list[str])->list[Tensor]:\n",
    "    x_filtered=[]\n",
    "    for k, v in out.items():\n",
    "        if k in featmap_names: x_filtered.append(v)\n",
    "    return x_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11914ad2-c862-4f88-bac6-4fc1764f1080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _infer_scale(feature: Tensor, original_size:list[int])->float:\n",
    "    # assumption: the scale is of the form 2 ** (-k), with k integer\n",
    "    size=feature.shape[-2:]\n",
    "    possible_scales:list[float]=[]\n",
    "    for s1, s2 in zip(size, original_size):\n",
    "        approx_scale=float(s1)/float(s2)\n",
    "        # print(f'In _infer_scale torch.tensor(approx_scale).log2(){torch.tensor(approx_scale).log2()}')\n",
    "        scale=2**float(torch.tensor(approx_scale).log2().round())\n",
    "        possible_scales.append(scale)\n",
    "        print('s1 ', s1, ' s2 ', s2, ' scale ', scale, ' s1/s2 ', s1/s2, flush=True)\n",
    "    return possible_scales[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96759c9-1ec1-4676-8d91-37c41fde00f2",
   "metadata": {},
   "source": [
    "[`setup_scales`](https://github.com/pytorch/vision/blob/main/torchvision/ops/poolers.py#L110)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39e69681-f3c9-4d60-a197-8e1cacf56f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _setup_scales(features:list[Tensor], image_shapes:list[tuple[int, int]], canonical_scale:int,\n",
    "                 canonical_level:int)->tuple[list[float], LevelMapper]:\n",
    "\n",
    "    if not image_shapes: raise ValueError('image size list should not be empty')\n",
    "    max_x=max_y=0\n",
    "    for shape in image_shapes:\n",
    "        max_x=max(shape[0], max_x)\n",
    "        max_y=max(shape[1], max_y)\n",
    "    original_input_shape=(max_x, max_y)\n",
    "    scales=[_infer_scale(feat, original_input_shape) for feat in features]\n",
    "    # get the levels in the feature map by leveraging the fact that the network always\n",
    "    # downsamples by a factor of 2 at each level\n",
    "    lvl_min=-torch.log2(torch.tensor(scales[0], dtype=torch.float32)).item()\n",
    "    lvl_max=-torch.log2(torch.tensor(scales[-1], dtype=torch.float32)).item()\n",
    "    print('original_input_shape ', original_input_shape)\n",
    "    map_levels=LevelMapper(int(lvl_min), int(lvl_max), canonical_scale=canonical_scale,\n",
    "                      canonical_level=canonical_level)\n",
    "    return scales, map_levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93e079aa-736a-48e8-b261-bd6d24bce393",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScaleRoIAlign(nn.Module):\n",
    "    # reference from https://github.com/pytorch/vision/blob/main/torchvision/ops/poolers.py\n",
    "    def __init__(self, \n",
    "                 featmap_names: list[str], \n",
    "                 output_size: Union[int, tuple[int], list[int]],\n",
    "                 sampling_ratio: int,\n",
    "                 *,\n",
    "                 canonical_scale:int=224,\n",
    "                 canonical_level:int=4):\n",
    "\n",
    "        super().__init__()\n",
    "        if isinstance(output_size, int): output_size=(output_size, output_size)\n",
    "        self.featmap_names=featmap_names\n",
    "        self.sampling_ratio=sampling_ratio\n",
    "        self.output_size=tuple(output_size)\n",
    "        self.scales=None\n",
    "        self.map_levels=None\n",
    "        self.canonical_scale=canonical_scale\n",
    "        self.canonical_level=canonical_level\n",
    "    def forward(self, \n",
    "               x: dict[str: Tensor],\n",
    "               boxes: list[Tensor], \n",
    "               image_shapes: list[tuple[int, int]])->Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (dict[Tensor]): feature maps for each level. They are assumed to have all the same number of \n",
    "                channels, but they can have different sizes\n",
    "            boxes (List[Tensor[N,4]]): boxes to be used to to perform the pooling operation, in (x1,y1,x2,y2) format and\n",
    "                in the image refence size, not the feature map reference. The coordinate must satisfy ``0<=x1<x2`` and\n",
    "                ``0<=y1<y2``\n",
    "            image_shapes (List[Tuple[height, width]]): the sizes of each image before they have been fed to a CNN to obtain feature maps.\n",
    "                This allows us to infor the scale factor for each one of the levels to be pooled\n",
    "        Returns:\n",
    "            result (Tensor)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "box_roi_pool=box_roi_pool=MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], \n",
    "                                             output_size=(7, 7), sampling_ratio=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d797bc4-8409-4b92-8a56-90367cedf489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1  200  s2  800  scale  0.25  s1/s2  0.25\n",
      "s1  296  s2  1159  scale  0.25  s1/s2  0.2553925798101812\n",
      "s1  100  s2  800  scale  0.125  s1/s2  0.125\n",
      "s1  148  s2  1159  scale  0.125  s1/s2  0.1276962899050906\n",
      "s1  50  s2  800  scale  0.0625  s1/s2  0.0625\n",
      "s1  74  s2  1159  scale  0.0625  s1/s2  0.0638481449525453\n",
      "s1  25  s2  800  scale  0.03125  s1/s2  0.03125\n",
      "s1  37  s2  1159  scale  0.03125  s1/s2  0.03192407247627265\n",
      "original_input_shape  (800, 1159)\n",
      "box_roi_pool.scales  [0.25, 0.125, 0.0625, 0.03125]\n"
     ]
    }
   ],
   "source": [
    "x=out\n",
    "x_filtered=_filter_input(x, box_roi_pool.featmap_names)\n",
    "if box_roi_pool.scales is None or box_roi_pool.map_levels is None:\n",
    "    box_roi_pool.scales, box_roi_pool.map_levels=_setup_scales(x_filtered, image_shapes,\n",
    "                        box_roi_pool.canonical_scale, box_roi_pool.canonical_level)\n",
    "print('box_roi_pool.scales ', box_roi_pool.scales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5723d217-6ade-48c4-a664-0bd12527fc1f",
   "metadata": {},
   "source": [
    "```\n",
    " _multiscale_roi_align(\n",
    "            x_filtered,\n",
    "            boxes,\n",
    "            self.output_size,\n",
    "            self.sampling_ratio,\n",
    "            self.scales,\n",
    "            self.map_levels,\n",
    "        )\n",
    "```\n",
    "[_multiscale_roi_align](https://github.com/pytorch/vision/blob/main/torchvision/ops/poolers.py#L147)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "100be5bd-c333-48ba-be7b-d55605e93b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxes  <class 'list'> [torch.Size([801, 4]), torch.Size([803, 4])]\n",
      "output_size  (7, 7)\n",
      "scales  [0.25, 0.125, 0.0625, 0.03125]\n",
      "mapper  <torchvision.ops.poolers.LevelMapper object at 0x0000016510256CD0> 2 5\n"
     ]
    }
   ],
   "source": [
    "boxes=proposals\n",
    "output_size=box_roi_pool.output_size\n",
    "sampling_ratio=box_roi_pool.sampling_ratio\n",
    "scales=box_roi_pool.scales\n",
    "mapper=box_roi_pool.map_levels\n",
    "print('boxes ', type(boxes), [b.shape for b in boxes])\n",
    "print('output_size ', output_size)\n",
    "print('scales ', scales)\n",
    "print('mapper ', mapper, mapper.k_min, mapper.k_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4eb4c92-e8f3-4078-a362-dd8468a798bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_levels  4\n",
      "x_filtered  <class 'list'>\n",
      "img_ids  torch.Size([1604, 1])\n",
      "rois  torch.Size([1604, 5])\n"
     ]
    }
   ],
   "source": [
    "if any(x is None for x in [scales, mapper]):\n",
    "    raise ValueError('scales and mapper should not be None')\n",
    "\n",
    "num_levels=len(x_filtered)\n",
    "print('num_levels ', num_levels)\n",
    "print('x_filtered ', type(x_filtered))\n",
    "\n",
    "# _convert_to_roi_format https://github.com/pytorch/vision/blob/main/torchvision/ops/poolers.py#L87\n",
    "concat_boxes=torch.cat(boxes, dim=0) # Nx4\n",
    "device, dtype=concat_boxes.device, concat_boxes.dtype\n",
    "\n",
    "# create ids for a set of boxes of each image so we know which boxes for which image \n",
    "img_ids=torch.cat(\n",
    "    [torch.full_like(b[:,:1], i, dtype=dtype, layout=torch.strided,device=device) for i, b in enumerate(boxes)],\n",
    "    dim=0\n",
    ")\n",
    "print('img_ids ', img_ids.shape)\n",
    "\n",
    "rois = torch.cat([img_ids, concat_boxes], dim=1) # Nx5\n",
    "print('rois ', rois.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2386841f-ed98-400b-8aec-07149923f89e",
   "metadata": {},
   "source": [
    "```\n",
    "levels=mapper(boxes)\n",
    "```\n",
    "[`__call__`](https://github.com/pytorch/vision/blob/main/torchvision/ops/poolers.py#L87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03897191-a251-4956-8852-b77a7794156e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s  torch.Size([1604]) 8.276786804199219 797.4650268554688\n",
      "lvl0  4  s0  224  eps  1e-06\n",
      "target_lvls  torch.Size([1604]) -1.0 5.0\n",
      "k_min  2  k_max  5\n",
      "levels  torch.Size([1604]) 0 3\n"
     ]
    }
   ],
   "source": [
    "boxlists=boxes\n",
    "\n",
    "# compute geometric mean area\n",
    "box_area=lambda boxlist: (boxlist[..., 2] - boxlist[..., 0]) * (boxlist[..., 3] - boxlist[..., 1])\n",
    "s=torch.sqrt(torch.cat([box_area(boxlist) for boxlist in boxlists])) # 1D tensor\n",
    "print('s ', s.shape, s.min().item(), s.max().item())\n",
    "# Eqn.1 in FPN paper\n",
    "print('lvl0 ', mapper.lvl0, ' s0 ', mapper.s0, ' eps ', mapper.eps)\n",
    "target_lvls=torch.floor(mapper.lvl0+torch.log2(s/mapper.s0)+torch.tensor(mapper.eps, dtype=s.dtype))\n",
    "print('target_lvls ', target_lvls.shape, target_lvls.min().item(), target_lvls.max().item())\n",
    "print('k_min ', mapper.k_min, ' k_max ', mapper.k_max)\n",
    "target_lvls=torch.clamp(target_lvls, min=mapper.k_min, max=mapper.k_max)\n",
    "# why do we delete k_min from level?\n",
    "# ChatGPT said they did this for indexing purposes. So index start at 0\n",
    "# So if level=0, ROI is place to index to 0 which mapped directly to the first feature map\n",
    "levels=(target_lvls.to(torch.int64)-mapper.k_min).to(torch.int64) \n",
    "print('levels ', levels.shape, levels.min().item(), levels.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "535f38cf-4b0e-47e9-bb3b-29780a209953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_rois  1604  num_channels  256  x_filtered  [torch.Size([2, 256, 200, 296]), torch.Size([2, 256, 100, 148]), torch.Size([2, 256, 50, 74]), torch.Size([2, 256, 25, 37])]\n"
     ]
    }
   ],
   "source": [
    "num_rois=len(rois)\n",
    "num_channels=x_filtered[0].shape[1]\n",
    "print('num_rois ', num_rois, ' num_channels ', num_channels, ' x_filtered ', [i.shape for i in x_filtered])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4eb0b35-ef6b-42e2-9c89-dae1c3917bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result  torch.Size([1604, 256, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "device,dtype=x_filtered[0].device, x_filtered[0].dtype\n",
    "result=torch.zeros( (num_rois, num_channels)+output_size, dtype=dtype, device=device)\n",
    "print('result ', result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5db7f411-006a-46fe-8d16-b1a1380c9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate from feature extracted from finer image to feature extracted from coarser image\n",
    "for level, (per_level_feature, scale) in enumerate(zip(x_filtered, scales)): \n",
    "    idx_in_level=torch.nonzero(levels==level, as_tuple=True)[0]\n",
    "    rois_per_level=rois[idx_in_level]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d1befc7-5702-4154-b3e7-3d7da8de9ed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   6,    9,   10,   12,   13,   17,   21,   23,   24,   25,   26,   27,\n",
       "          29,   30,   32,   35,   36,   37,   40,   41,   42,   43,   45,   46,\n",
       "          48,   50,   51,   53,   54,   55,   56,   57,   59,   60,   61,   65,\n",
       "          66,   67,   69,   70,   72,   73,   76,   77,   78,   79,   80,   81,\n",
       "          83,   85,   86,   88,   89,   91,   92,   93,   95,   96,   97,   98,\n",
       "          99,  100,  101,  102,  103,  104,  106,  107,  108,  109,  110,  111,\n",
       "         112,  113,  115,  116,  118,  119,  120,  121,  122,  123,  126,  128,\n",
       "         129,  130,  131,  132,  134,  135,  136,  137,  138,  139,  140,  141,\n",
       "         142,  143,  144,  146,  147,  149,  150,  151,  152,  154,  155,  156,\n",
       "         157,  158,  159,  160,  161,  162,  163,  164,  165,  166,  167,  168,\n",
       "         169,  170,  171,  172,  173,  175,  176,  177,  178,  180,  181,  183,\n",
       "         185,  186,  187,  188,  189,  190,  191,  192,  193,  196,  197,  198,\n",
       "         199,  201,  202,  203,  204,  205,  207,  209,  210,  212,  213,  214,\n",
       "         217,  218,  219,  220,  221,  222,  223,  224,  225,  227,  228,  229,\n",
       "         231,  232,  233,  234,  235,  236,  237,  238,  239,  240,  241,  242,\n",
       "         243,  245,  247,  248,  249,  251,  253,  255,  257,  258,  260,  261,\n",
       "         262,  263,  264,  265,  267,  268,  269,  270,  271,  273,  274,  275,\n",
       "         276,  278,  279,  280,  282,  283,  284,  285,  287,  288,  290,  291,\n",
       "         293,  294,  295,  296,  297,  298,  299,  300,  301,  302,  303,  304,\n",
       "         305,  307,  308,  309,  311,  312,  313,  314,  315,  317,  318,  319,\n",
       "         320,  321,  322,  323,  324,  327,  328,  329,  330,  331,  332,  333,\n",
       "         334,  335,  338,  339,  340,  341,  342,  343,  344,  346,  347,  348,\n",
       "         350,  351,  352,  353,  354,  355,  356,  357,  358,  359,  360,  361,\n",
       "         362,  363,  364,  365,  366,  367,  368,  369,  370,  371,  372,  373,\n",
       "         374,  375,  376,  378,  379,  381,  382,  384,  386,  388,  392,  394,\n",
       "         396,  399,  400,  401,  403,  405,  406,  407,  408,  409,  410,  411,\n",
       "         412,  414,  415,  416,  417,  418,  421,  422,  423,  425,  426,  427,\n",
       "         428,  429,  430,  431,  433,  434,  435,  436,  437,  438,  439,  442,\n",
       "         443,  444,  445,  446,  447,  448,  449,  450,  451,  453,  454,  455,\n",
       "         456,  457,  458,  461,  462,  463,  464,  465,  466,  469,  470,  474,\n",
       "         475,  476,  478,  479,  481,  482,  483,  484,  485,  486,  488,  489,\n",
       "         490,  491,  492,  493,  494,  495,  496,  497,  498,  499,  500,  501,\n",
       "         502,  503,  504,  505,  506,  508,  509,  510,  511,  512,  513,  515,\n",
       "         516,  517,  519,  520,  521,  522,  523,  525,  526,  529,  530,  531,\n",
       "         532,  533,  534,  535,  536,  538,  539,  541,  542,  543,  544,  546,\n",
       "         547,  548,  549,  550,  551,  552,  553,  554,  555,  557,  558,  559,\n",
       "         560,  561,  562,  563,  564,  565,  567,  568,  569,  570,  571,  572,\n",
       "         573,  574,  575,  576,  577,  578,  579,  580,  581,  582,  583,  584,\n",
       "         585,  586,  587,  588,  590,  591,  592,  593,  594,  595,  596,  597,\n",
       "         598,  600,  601,  602,  603,  605,  608,  609,  614,  617,  621,  622,\n",
       "         633,  638,  645,  673,  689,  695,  697,  722,  723,  725,  743,  752,\n",
       "         754,  755,  762,  781,  786,  787,  795,  796,  829,  831,  832,  833,\n",
       "         848,  849,  850,  854,  855,  857,  859,  860,  867,  871,  874,  879,\n",
       "         881,  887,  888,  889,  892,  894,  896,  897,  898,  900,  902,  903,\n",
       "         906,  910,  915,  916,  917,  919,  920,  922,  924,  926,  927,  928,\n",
       "         931,  933,  934,  939,  943,  945,  949,  950,  951,  955,  957,  961,\n",
       "         963,  964,  965,  966,  967,  971,  972,  973,  974,  975,  976,  977,\n",
       "         978,  982,  983,  984,  987,  988,  990,  995,  997, 1000, 1001, 1003,\n",
       "        1011, 1012, 1013, 1015, 1017, 1019, 1021, 1023, 1026, 1028, 1029, 1033,\n",
       "        1034, 1035, 1037, 1039, 1041, 1042, 1043, 1044, 1045, 1047, 1050, 1052,\n",
       "        1054, 1058, 1062, 1063, 1070, 1071, 1072, 1075, 1077, 1078, 1081, 1083,\n",
       "        1085, 1086, 1087, 1088, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097,\n",
       "        1098, 1099, 1101, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1111, 1113,\n",
       "        1114, 1116, 1117, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1131,\n",
       "        1133, 1134, 1135, 1138, 1139, 1142, 1143, 1144, 1145, 1146, 1149, 1150,\n",
       "        1151, 1153, 1156, 1157, 1159, 1163, 1164, 1165, 1166, 1167, 1168, 1175,\n",
       "        1177, 1179, 1180, 1183, 1184, 1185, 1189, 1190, 1191, 1192, 1194, 1196,\n",
       "        1198, 1199, 1201, 1203, 1204, 1206, 1207, 1208, 1209, 1212, 1213, 1214,\n",
       "        1215, 1218, 1220, 1223, 1224, 1226, 1227, 1228, 1229, 1231, 1233, 1238,\n",
       "        1241, 1242, 1246, 1247, 1248, 1250, 1251, 1252, 1253, 1255, 1257, 1259,\n",
       "        1262, 1266, 1269, 1270, 1272, 1273, 1274, 1275, 1276, 1278, 1279, 1283,\n",
       "        1284, 1285, 1287, 1288, 1289, 1290, 1291, 1293, 1295, 1297, 1298, 1300,\n",
       "        1302, 1303, 1305, 1307, 1309, 1310, 1311, 1313, 1314, 1315, 1316, 1317,\n",
       "        1318, 1319, 1321, 1324, 1325, 1326, 1328, 1331, 1332, 1333, 1334, 1336,\n",
       "        1339, 1341, 1343, 1346, 1348, 1350, 1352, 1353, 1357, 1360, 1361, 1362,\n",
       "        1363, 1365, 1369, 1371, 1381, 1385, 1394, 1395, 1400, 1404, 1406, 1411,\n",
       "        1412, 1415, 1417, 1418, 1419, 1421, 1422, 1424, 1429, 1430, 1432, 1435,\n",
       "        1437, 1438, 1440, 1442, 1443, 1444, 1446, 1447, 1458, 1459, 1461, 1462,\n",
       "        1463, 1464, 1465, 1466, 1473, 1475, 1478, 1479, 1480, 1481, 1484, 1487,\n",
       "        1489, 1492, 1502, 1505, 1507, 1509, 1512, 1513, 1516, 1517, 1518, 1519,\n",
       "        1521, 1523, 1524, 1526, 1527, 1528, 1529, 1535, 1536])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_in_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8890d58e-1cc0-4201-9a44-1fa116c2d06b",
   "metadata": {},
   "source": [
    "[roi_align](https://github.com/pytorch/vision/blob/main/torchvision/ops/roi_align.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72d5e4e0-14fe-4b8d-8653-52f7626fc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling_ratio  2  output_size  (7, 7)\n"
     ]
    }
   ],
   "source": [
    "input=per_level_feature\n",
    "boxes=rois_per_level\n",
    "spatial_scale=scale\n",
    "aligned=False\n",
    "print('sampling_ratio ', sampling_ratio, ' output_size ', output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e13047c-4998-4941-8325-eaa9b06dc1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rois  <class 'torch.Tensor'> torch.Size([849, 5])\n"
     ]
    }
   ],
   "source": [
    "rois=boxes\n",
    "print('rois ', type(rois), rois.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826482f8-d2ee-4067-909a-1e281e25f293",
   "metadata": {},
   "source": [
    "[_roi_align](https://github.com/pytorch/vision/blob/main/torchvision/ops/roi_align.py#L9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f339d17-b304-422b-8e0b-3fd9814c98bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roi_width  torch.Size([849]) 0.70745849609375 120.55207824707031\n",
      "roi_height  torch.Size([849]) 0.6410369873046875 127.11204528808594\n",
      "roi_width  torch.Size([849]) 1.0 120.55207824707031\n",
      "roi_height  torch.Size([849]) 1.0 127.11204528808594\n"
     ]
    }
   ],
   "source": [
    "pooled_height=output_size[0] \n",
    "pooled_width=output_size[1] \n",
    "\n",
    "orig_dtype=input.dtype\n",
    "_,_,height,width=input.size()\n",
    "ph=torch.arange(pooled_height,device=input.device) # [PH]\n",
    "pw=torch.arange(pooled_width, device=input.device) # [PW]\n",
    "\n",
    "# input: [N,C,H,W]\n",
    "# rois: [K, 5]\n",
    "\n",
    "roi_batch_ind=rois[:,0].int() # [k]\n",
    "offset=0.5 if aligned else 0.\n",
    "# where spatial scale tell how much smaller features compared to image\n",
    "roi_start_w=rois[:,1]*spatial_scale - offset # [K]\n",
    "roi_start_h=rois[:,2]*spatial_scale - offset # [K]\n",
    "roi_end_w=rois[:,3]*spatial_scale-offset # [K]\n",
    "roi_end_h=rois[:,4]*spatial_scale-offset # [K]\n",
    "\n",
    "roi_width=roi_end_w-roi_start_w  # [K]\n",
    "roi_height=roi_end_h-roi_start_h # [K]\n",
    "print('roi_width ', roi_width.shape, roi_width.min().item(), roi_width.max().item())\n",
    "print('roi_height ', roi_height.shape, roi_height.min().item(), roi_height.max().item())\n",
    "\n",
    "if not aligned:\n",
    "    roi_width=torch.clamp(roi_width,  min=1.0) # [K]\n",
    "    roi_height=torch.clamp(roi_height, min=1.0) # [K]\n",
    "print('roi_width ', roi_width.shape, roi_width.min().item(), roi_width.max().item())\n",
    "print('roi_height ', roi_height.shape, roi_height.min().item(), roi_height.max().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03ecc7f5-c8db-4e16-88e3-ba06be666a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin_size_h  tensor([ 1.8297,  3.0553,  4.6488,  3.6692,  4.0668,  4.0846,  2.4883,  3.6748,\n",
      "         1.6789,  1.8744,  3.6051,  1.6295,  3.2082,  4.3968,  3.7302,  4.4600,\n",
      "         3.3769,  2.6490,  3.4099,  3.7661,  3.2102,  2.8646,  4.4398,  4.0115,\n",
      "         3.5923,  2.5295,  3.3016,  2.0284,  3.6113,  2.8184,  4.2214,  3.4182,\n",
      "         2.1966,  2.6943,  3.5541,  2.0056,  2.2153,  2.0122,  3.8218,  1.9553,\n",
      "         2.3758,  2.3740,  2.8747,  2.8402,  2.5494,  4.7609,  2.6205,  2.0872,\n",
      "         2.4516,  4.0521,  3.7127,  4.4879,  4.5062,  2.8869,  2.8347,  3.8302,\n",
      "         2.9499,  2.4357,  2.1665,  2.8879,  2.5705,  2.7838,  1.5856,  2.1666,\n",
      "         3.8744,  2.6102,  2.7108,  2.9725,  1.6692,  3.1174,  1.5822,  2.8359,\n",
      "         2.8920,  4.1371,  4.8053,  2.6567,  3.1036,  4.7339,  2.6632,  2.6439,\n",
      "         2.7375,  2.2078,  3.7429,  2.4996,  3.5402,  2.0305,  4.5843,  0.4955,\n",
      "         2.6215,  2.9558,  1.5014,  3.4609,  2.9567,  1.5572,  3.1574,  2.3630,\n",
      "         2.6275,  2.0698,  2.6748,  2.7117,  2.2860,  3.3958,  1.5489,  1.9335,\n",
      "         1.6545,  2.0480,  3.1278,  3.1828,  5.0641,  2.8186,  3.6674,  2.4176,\n",
      "         2.4163,  2.3744,  2.5734,  1.7359,  2.9538,  1.9620,  4.3844,  2.1215,\n",
      "         2.7347,  0.4752,  1.4141,  3.0788,  1.7032,  0.4558,  5.0646,  1.5090,\n",
      "         0.5112,  2.8517,  1.7574,  3.5454,  4.5549,  4.0225,  2.7206,  2.0235,\n",
      "         3.9687,  2.7632,  1.8842,  6.6960,  2.2728,  2.2030,  3.7990,  1.7446,\n",
      "         2.7541,  1.2186,  2.4110,  2.1572,  2.7999,  1.9345,  3.2666,  0.5747,\n",
      "         1.5125,  3.4233,  1.6755,  1.7926,  1.5364,  2.7003,  2.6184,  0.6039,\n",
      "         3.7103,  2.8696,  1.7350,  3.8805,  3.8084,  2.4071,  2.7762,  1.5019,\n",
      "         2.6660,  6.5516,  2.6287,  0.8463,  1.9520,  0.5486,  0.5151,  1.1474,\n",
      "         2.1055,  3.5475,  2.6567,  4.5212,  3.1526,  3.2675,  1.9125,  2.3257,\n",
      "         1.7431,  1.5949,  2.0619,  1.5751,  1.7094,  0.8534,  0.6082,  2.0991,\n",
      "         1.8914,  1.6338,  2.7216,  0.5462,  1.3045,  2.4455,  3.6259,  2.9963,\n",
      "         3.1149,  2.2325,  1.6751,  3.0578,  1.3855,  2.6313,  3.6806,  2.4431,\n",
      "         0.4988,  0.4836,  0.5090,  1.5005,  0.7349,  4.9215,  2.0764,  2.5024,\n",
      "         1.2913,  2.0605,  3.1214,  1.7722,  1.1661,  1.7611,  1.5022,  3.7300,\n",
      "         2.7603,  3.7288,  1.1808,  1.3312,  0.6714,  0.5057,  2.4302,  1.9960,\n",
      "         2.1893,  8.0134,  0.6360,  2.2199,  3.7376,  1.5007,  4.5801,  2.9347,\n",
      "         2.0139,  2.4737,  0.4700,  2.2761,  0.4570,  3.3449,  1.5084,  1.6897,\n",
      "         1.1032,  3.1805,  0.4661,  3.7961,  1.7944,  2.7942,  1.4989,  1.9278,\n",
      "         5.4171,  0.6383,  1.2398,  1.4605,  0.5881,  1.7679,  3.7674,  3.9777,\n",
      "         1.9890,  2.4540,  1.4018,  2.9050,  4.0310,  2.1114,  2.8261,  0.6196,\n",
      "         2.2537,  3.8992,  0.4214,  1.7266,  0.5552,  0.4911,  2.1955,  4.8555,\n",
      "         0.3562,  0.4816,  4.9728,  2.5482,  2.1394,  1.4353,  3.0738,  0.8894,\n",
      "         0.3763,  0.5110,  3.4243,  4.3412,  2.7663,  2.8152,  0.5337,  0.2971,\n",
      "         1.8033,  3.7821,  1.4985,  2.5653,  2.4712,  2.0013,  2.3696,  1.5393,\n",
      "         0.4480,  2.5952,  0.2846,  5.7244,  4.1895,  0.4883,  0.4621,  1.9197,\n",
      "         0.2999,  0.8465,  2.0904,  3.7112,  0.4417,  0.4964,  1.0693,  3.7236,\n",
      "         1.4278,  1.7350,  1.6229,  0.3357,  0.9823,  6.0099,  2.0819,  3.6746,\n",
      "         0.6218,  0.6158,  0.6321,  2.9100,  0.5207,  2.5429,  2.8290,  2.4370,\n",
      "         2.3650,  3.2562,  0.6415,  1.6152,  1.5959,  0.4786,  1.3172,  2.1678,\n",
      "         1.2187,  0.7036,  0.3850,  1.3088,  2.3741,  1.7751,  2.5981,  1.2700,\n",
      "         3.5876,  0.6002,  1.4652,  0.8618,  1.7328,  4.0055,  2.3733,  0.3362,\n",
      "         0.6087,  4.9590,  9.2676,  2.4530,  3.8183,  1.2179,  0.7249,  0.6897,\n",
      "         1.3753,  1.4167,  0.5642,  2.7897,  3.5506,  3.8487,  3.9944,  0.8947,\n",
      "         0.8453,  1.4657,  2.4261,  1.7438,  0.4553,  4.2654,  0.6257,  0.5305,\n",
      "         2.2004,  2.0796,  3.7181,  5.4845,  0.9989,  2.3554,  2.1627,  0.5798,\n",
      "         2.3384,  1.9546,  0.1464,  1.3255,  3.0122,  0.8577,  1.6618,  0.4501,\n",
      "         2.1581,  1.8103,  2.3615,  4.8769,  1.1071,  0.8107,  1.0590,  1.2253,\n",
      "         1.3012,  2.7266,  2.4081,  4.5943,  1.6638,  4.9245,  0.7905,  3.9497,\n",
      "         1.3861,  0.7181,  0.4850,  0.6439,  2.0137,  0.6250,  2.2859,  2.0543,\n",
      "         1.3933,  3.7692,  0.6997,  1.5836,  1.4306,  1.0198,  2.7209,  0.5853,\n",
      "         1.4797,  6.3291,  0.3284,  1.9871,  3.1649,  1.4154,  1.3310,  2.0517,\n",
      "         5.8047,  1.9459,  1.6968,  0.5006,  1.0775,  2.2058,  2.2085,  0.4832,\n",
      "         2.5452,  1.6549,  1.6878,  1.9677,  0.3380,  0.5052,  0.5042,  4.0433,\n",
      "         2.5306,  1.9655,  2.6507,  1.5217,  0.5524,  1.5730,  0.7030,  1.8309,\n",
      "         2.4919,  1.3576,  3.4160,  4.0609,  3.6228,  0.8553,  2.2440,  6.5067,\n",
      "         2.6185,  2.5921,  4.2389,  2.3229,  9.7693,  4.1122,  4.9368,  3.7208,\n",
      "         3.0900,  5.1689,  2.8304,  2.8172,  2.8511,  4.0095,  2.9526,  3.9011,\n",
      "         3.4922,  3.8573,  3.7144,  5.7526,  6.3600,  3.1465,  5.2675,  3.1706,\n",
      "         2.7419,  3.5800,  6.0598,  3.4068,  2.0171,  2.3018,  3.8707,  0.7278,\n",
      "         4.9025,  0.6485,  0.6369,  0.6726,  3.6050,  0.6698,  0.5763,  2.8074,\n",
      "         0.5391,  4.0647,  1.0590,  0.5918,  2.0617,  3.0296,  0.2462,  2.1620,\n",
      "         2.6764,  2.7652,  0.5103,  6.1764,  0.5982,  2.6384,  2.6424,  0.5691,\n",
      "         4.3562,  2.8201,  0.1562,  2.3200,  0.1933,  0.7327,  1.8366,  4.6575,\n",
      "         2.0763,  5.5049,  0.4963,  0.6611,  0.3771,  3.4839,  0.1429,  0.4741,\n",
      "         6.0079,  0.3053,  0.5905,  0.5539,  0.5905,  0.1725,  1.1576,  2.0971,\n",
      "         0.2261,  3.2204,  2.5867,  0.3032,  0.3836,  0.8665,  5.2382,  2.5542,\n",
      "         0.2492,  2.2622,  2.6298,  0.5386,  0.7212,  0.1859,  0.4269,  0.2520,\n",
      "         1.6431,  0.5524,  6.5290,  1.9121,  0.2488,  3.8884,  0.5692,  0.6870,\n",
      "         0.5293,  1.7933,  0.5660,  1.9584,  0.6991,  2.7224,  1.0590,  0.3996,\n",
      "         3.2276,  4.5012,  0.4537,  0.5913,  0.5849,  0.5239,  2.7078,  1.4090,\n",
      "         0.4591,  2.4490,  0.1429,  0.4593,  1.1008,  0.4891,  0.5258,  4.4740,\n",
      "         5.2892,  0.6453,  3.4034,  0.1866,  4.4394,  2.3640,  3.3544,  0.5319,\n",
      "         1.9849,  2.8920,  0.3504,  2.8927,  1.1958,  1.8461,  2.6990,  0.3996,\n",
      "         2.9769,  0.5951,  1.7688,  2.6885,  0.6022,  4.5619,  1.9387,  3.4773,\n",
      "         1.8968,  1.4601,  5.0985,  0.4549,  0.3780,  2.1878,  1.2062,  0.4013,\n",
      "         0.5831,  3.5097,  0.9959,  0.9121,  1.2804,  0.5298,  3.9174,  5.8254,\n",
      "         0.5518,  2.0786,  1.9025,  1.8526,  2.7660,  0.4922,  2.4083,  3.5128,\n",
      "         0.1974,  0.5103,  1.7625,  0.1429,  0.4015,  0.4679,  1.2509,  0.6347,\n",
      "         0.3878,  0.5786,  0.5761,  1.9064,  6.6042,  1.7067,  0.4650,  0.4667,\n",
      "         2.9947,  0.5915,  0.1789,  0.5678,  0.6023,  0.5963,  5.8892,  0.1429,\n",
      "         0.1429,  2.8261,  0.3302,  0.5679,  0.4798,  0.3976,  1.0069,  1.8096,\n",
      "         2.0569,  0.1429,  5.3073,  0.4937,  0.2013,  0.9319,  1.8062,  2.4775,\n",
      "         0.4478,  3.1234,  1.9725,  0.1492,  4.3925,  0.5505,  6.1771,  0.6367,\n",
      "         0.5602,  0.1429,  0.6809,  0.5601,  1.4768,  3.4210,  4.8847,  0.4952,\n",
      "         0.9253,  1.7880,  0.1429,  0.3883,  1.6050,  1.6597,  2.3929,  2.5175,\n",
      "         1.1544,  0.4509,  1.1337,  0.7229,  1.2003,  0.2157,  0.5012,  3.2842,\n",
      "         0.1429,  1.4724,  0.1530,  0.1429,  1.4551,  1.4483,  0.1805,  0.1429,\n",
      "         8.5334,  2.6905,  2.7331,  0.5350,  2.2653,  0.1437,  1.0606,  3.0323,\n",
      "         0.4968,  1.3891,  0.4702,  1.4681,  0.3724,  0.5186,  1.4735,  0.4784,\n",
      "         0.2464,  1.8376,  1.3912,  0.1429,  0.5248,  0.4627,  2.6436,  0.6417,\n",
      "        14.8288,  2.0416,  2.3891,  0.1429,  1.7774,  0.8449,  2.4187,  0.9022,\n",
      "         0.8752,  0.5395,  0.1679,  0.8066,  1.0737,  4.8644,  0.3238,  1.1778,\n",
      "         0.2868,  0.4989,  1.0908,  0.1632,  0.4209,  0.4786,  1.9662,  0.8641,\n",
      "         3.9008,  6.4897,  0.4258,  3.8434,  0.5938,  3.0992,  0.3644,  4.0285,\n",
      "         0.9195,  2.3792,  2.2281,  1.6510,  3.4013,  0.9266,  4.0713, 17.1368,\n",
      "         7.0484,  0.3567,  4.4674,  0.5093,  0.9146,  0.4262, 17.3534,  1.6993,\n",
      "         6.0504,  2.2685,  2.4506,  1.6630,  9.8650,  0.9533,  2.4303,  4.6649,\n",
      "         0.4628,  1.7254,  3.1760, 10.6938,  5.3100,  3.5619, 12.0154,  1.3529,\n",
      "         1.3928,  1.2385,  0.3300,  6.0375,  2.2323, 13.6242, 18.1589,  3.4376,\n",
      "         3.7590,  0.4480,  2.4480,  4.9178,  1.8854,  0.4319,  2.1416,  4.7698,\n",
      "         3.5593,  5.4048,  0.3737,  5.4411,  6.8895,  2.0242,  6.0510,  5.3439,\n",
      "         2.1969,  2.0385,  1.4217,  4.2642,  2.9739,  2.2441,  1.6141,  3.6332,\n",
      "         1.7272])  bin_size_w  tensor([ 0.9215,  1.6654,  2.8022,  1.4683,  3.7085,  2.2426,  2.7053,  2.1123,\n",
      "         0.9326,  0.9266,  3.8276,  1.2246,  4.9320,  1.7656,  3.9560,  2.7987,\n",
      "         2.2236,  1.3143,  1.8348,  1.2425,  1.8556,  3.1056,  3.0770,  1.3653,\n",
      "         1.3591,  1.4389,  2.7571,  0.3953,  2.1132,  2.6404,  1.0151,  0.6244,\n",
      "         1.7086,  2.5691,  2.1888,  1.5418,  0.4917,  0.2924,  1.3781,  0.3048,\n",
      "         3.3898,  3.7313,  1.4336,  1.5706,  2.7559,  2.9824,  0.5516,  1.0468,\n",
      "         0.3140,  2.0904,  2.1979,  3.0272,  2.5616,  2.8232,  1.3701,  2.4356,\n",
      "         1.6774,  2.0079,  2.1466,  1.2245,  0.5893,  0.4247,  1.2600,  3.7033,\n",
      "         2.3888,  2.8682,  0.3066,  1.7414,  1.3778,  1.8218,  1.3617,  2.7943,\n",
      "         2.9435,  2.9683,  2.5168,  2.2616,  1.8792,  2.8363,  0.3898,  2.5309,\n",
      "         2.5624,  2.1116,  2.0270,  3.6324,  3.0217,  3.9047,  2.2022,  0.6427,\n",
      "         0.2461,  2.8499,  1.4266,  2.4592,  2.7064,  0.8127,  2.4370,  3.5457,\n",
      "         2.1281,  1.5805,  4.3586,  0.2363,  1.9618,  0.5106,  0.7372,  1.6142,\n",
      "         0.9357,  1.0203,  0.7353,  0.6421,  2.4851,  2.6188,  4.1712,  2.0552,\n",
      "         1.2788,  1.9318,  2.1304,  0.9699,  4.9004,  3.6733,  2.3194,  1.0401,\n",
      "         2.6708,  0.4116,  1.2057,  4.9571,  1.3938,  0.6608,  1.1640,  0.8299,\n",
      "         0.5251,  2.8691,  4.0734,  1.1085,  1.1863,  2.2815,  2.3804,  3.9050,\n",
      "         2.1280,  2.3899,  1.5545,  1.9623,  2.0304,  1.8640,  2.0360,  3.7390,\n",
      "         0.8431,  7.2556,  1.2960,  1.8341,  2.5102,  1.7523,  1.8998,  0.5678,\n",
      "         0.8710,  0.3517,  1.3875,  1.9710,  1.2234,  0.8886,  2.7400,  0.9939,\n",
      "         0.1830,  2.8744,  4.1508,  0.7880,  1.8498,  3.8183,  1.5453,  0.6137,\n",
      "         2.6564,  0.9644,  2.2288,  1.7980,  3.8909,  0.6316,  0.4614,  1.1217,\n",
      "         1.9312,  0.2642,  2.2652,  1.7202,  1.7057,  2.4078,  1.6736,  1.8680,\n",
      "         1.3497,  0.8924,  1.0552,  3.8274,  1.3030,  0.9850,  0.8132,  1.5830,\n",
      "         1.7307,  3.6829,  1.2846,  0.7585,  1.4089,  1.9449,  1.8454,  1.6465,\n",
      "         1.5233,  2.5509,  0.8611,  0.7916,  1.1699,  1.4558,  2.1227,  2.4745,\n",
      "         0.9536,  0.7899,  0.5377,  0.7656,  0.7392,  2.8029,  1.0258,  2.7456,\n",
      "         4.3706,  3.5090,  1.6854,  1.7269,  6.0532,  1.9140,  0.8406,  1.6191,\n",
      "         2.6192,  1.8664,  0.7127,  0.7822,  1.0059,  0.5288,  2.0387,  3.2061,\n",
      "         1.5938,  0.7547,  0.6606,  0.9031,  2.3919,  0.5014,  0.8259,  0.7813,\n",
      "         1.9476,  2.5994,  0.6255,  1.7718,  0.5499,  1.8769,  0.7205,  1.2550,\n",
      "         1.1434,  1.8573,  0.9720,  2.0427,  4.1778,  0.8974,  0.9008,  1.7757,\n",
      "         2.7754,  0.8358,  1.5157,  1.6171,  1.4628,  1.2632,  3.8032,  0.1840,\n",
      "         3.6516,  0.9215,  1.3516,  4.9061,  1.6228,  0.8178,  2.7322,  0.6860,\n",
      "         0.8337,  1.5575,  1.1078,  1.3198,  1.0420,  0.3844,  2.1899,  0.1901,\n",
      "         0.4115,  0.4525,  0.1565,  2.7927,  3.7907,  1.2318,  0.3674,  1.9380,\n",
      "         1.0813,  0.8397,  1.1699,  0.2132,  2.8746,  2.6234,  0.6081,  0.3017,\n",
      "         2.8154,  2.1269,  1.3680,  2.5450,  2.3558,  2.0146,  2.1988,  1.1881,\n",
      "         0.6439,  0.8308,  0.3071,  0.2058,  3.1054,  1.0054,  0.4380,  3.7546,\n",
      "         0.3428,  0.8918,  1.0636,  2.2592, 12.0826,  0.9576,  0.7350,  1.9736,\n",
      "         0.8003,  3.4223,  0.9534,  0.4321,  1.0157,  0.6720,  0.6073,  1.4049,\n",
      "         0.8267,  1.4308,  1.0172,  1.4160,  1.0694,  2.6289,  2.3546,  1.4370,\n",
      "         0.9851,  1.5803,  0.8356,  1.5989,  0.8960,  0.5028,  1.4008,  0.9182,\n",
      "         0.6689,  0.9590,  0.4044,  0.8161,  2.6975,  1.3517,  2.2884,  1.2140,\n",
      "         3.2697,  0.7350,  1.1692,  0.7278,  1.3627,  1.6566,  0.6038,  1.3221,\n",
      "         0.7013,  0.1429,  0.6243,  1.8192,  1.6566,  0.8237,  1.7727,  0.9043,\n",
      "         1.2195,  0.6341,  0.9653,  0.8420,  1.9694,  2.0716,  1.6353,  2.1847,\n",
      "         1.5992,  3.0689,  2.8765,  1.2964,  0.9071,  1.6399,  0.7090,  1.0893,\n",
      "         0.8440,  1.7135,  1.8454,  2.5743,  0.5040,  2.0793,  2.0274,  0.5640,\n",
      "         3.3522,  2.1265,  9.0029,  1.2376,  1.5482,  2.1571,  4.7073,  1.1440,\n",
      "         1.9135,  3.4270,  2.5137,  2.1765,  0.5216,  1.5714,  0.6409,  7.1383,\n",
      "         0.8344,  2.3933,  2.1708,  1.5010,  2.6940,  2.8526,  2.3506,  1.5381,\n",
      "         0.5920,  1.2537,  1.0872,  0.6388,  1.8416,  0.8800,  3.1841,  2.1189,\n",
      "         5.1970,  2.3099,  1.1509,  1.3710,  1.3175,  1.0563,  0.6923,  0.6797,\n",
      "         0.9762,  0.1469,  1.6851,  1.7551,  2.0188,  1.4808,  2.9230,  1.9709,\n",
      "         0.1429,  2.0538,  3.4616,  0.5711,  0.8817,  1.0146,  2.0813,  0.4568,\n",
      "         1.4940,  1.2657,  0.9434,  0.8387,  2.2781,  0.7743,  0.8899,  2.4374,\n",
      "         0.9427,  1.2888,  0.8938,  1.3693,  1.4592,  0.8403,  1.0477,  0.8276,\n",
      "         0.9497,  1.2871,  1.6936,  1.9066,  2.4441,  0.7230,  2.0547,  0.1429,\n",
      "         1.6580,  3.3949,  1.7902,  3.3463,  1.3016,  3.7958,  2.0057,  3.7443,\n",
      "         4.5942,  2.3669,  4.4761,  5.2102,  5.4254,  3.3214,  4.9430,  2.2610,\n",
      "         4.3791,  4.0203,  3.0947,  2.5867,  2.2818,  5.0643,  2.7923,  3.4773,\n",
      "         5.4265,  4.4379,  2.3714,  4.0442,  1.8389,  2.3458,  1.6302,  0.3587,\n",
      "         1.3425,  0.3541,  0.3662,  0.3609,  1.7680,  0.3436,  0.3193,  2.4327,\n",
      "         0.2992,  1.3454,  0.9950,  0.4406,  1.1806,  1.6938,  4.5643,  2.2288,\n",
      "         0.7002,  0.6981,  0.3176,  2.5058,  0.3661,  0.5846,  0.5167, 10.4702,\n",
      "         2.6081,  1.2474,  6.9816,  1.5046,  5.5438,  8.5102,  3.0211,  1.3282,\n",
      "         2.9923,  1.6270, 13.0798,  0.5416,  3.4945,  0.6593,  6.8314,  3.4595,\n",
      "         2.6286,  3.6643,  0.5540,  0.4751,  0.3882,  7.6896,  1.0822,  2.1415,\n",
      "         4.9113,  1.4306,  0.5768,  4.1978,  3.7422,  0.5790,  1.4634,  0.5620,\n",
      "         3.9924,  2.1298,  0.4997,  0.4111,  8.2225,  5.9945, 11.7376,  4.4917,\n",
      "         1.5866, 10.1927,  2.4437,  3.0213,  4.6941,  1.6810,  0.5494,  0.2572,\n",
      "         0.3091,  1.9116,  0.3599,  0.6995,  0.3900,  1.9868,  0.6557,  0.3302,\n",
      "         0.4732,  1.5099,  0.3044,  0.5282,  0.3961,  0.2916,  4.7682,  1.3982,\n",
      "         4.2880,  0.5990,  6.4968,  0.3489,  1.0705,  0.4668,  0.5316,  3.5697,\n",
      "         1.3278,  8.4138,  0.6356,  5.0654,  1.7448,  0.5996,  0.5747,  0.3203,\n",
      "         1.0353,  0.6943,  0.3600,  1.0364,  1.1674,  0.6370,  1.6996,  0.4319,\n",
      "         0.5863,  0.4323,  1.5073,  0.6494,  0.2613,  1.5059,  1.9535,  1.4190,\n",
      "         0.6989,  3.0058,  1.3754,  0.3383,  0.3576,  0.7115,  6.0797,  0.4195,\n",
      "         0.4862,  1.3970,  1.0062,  6.5706,  0.7156,  0.4776,  3.5172,  1.6334,\n",
      "         0.5356,  4.1623,  0.5935,  3.1293,  2.5023,  0.3254,  0.6220,  3.1554,\n",
      "         5.6621,  0.3554,  0.8963,  8.3609, 13.7057,  0.3955,  1.1368,  0.4331,\n",
      "        13.2235,  0.4723,  0.4333,  3.5437,  2.3934,  5.5101,  0.3470,  4.3330,\n",
      "         0.5347,  0.3717,  5.1007,  0.5638,  0.3999,  0.4338,  2.3241,  5.9188,\n",
      "         7.3648,  0.7658, 15.8234,  0.4144,  0.2963,  0.3752,  6.3860,  2.6088,\n",
      "         0.7003,  8.2866,  1.5612,  0.3035,  5.8049,  0.7755,  4.1642,  0.5768,\n",
      "         0.3697,  2.2945,  0.6344,  6.4842,  1.1074,  0.4972,  2.4273,  0.2563,\n",
      "         0.5006,  8.4300,  0.8807,  0.5059,  1.5615,  1.9781,  1.1938,  3.9281,\n",
      "         6.8114,  0.8141,  6.3742,  1.2904,  1.5003,  5.2712,  1.1929,  0.8414,\n",
      "         5.6543,  0.3897,  6.1606,  0.5684,  1.2886,  4.0610, 13.7627,  2.3469,\n",
      "         8.0674,  0.6637,  6.7214,  7.9379,  1.3275,  6.2044,  5.9615,  6.8298,\n",
      "         0.1429,  2.5459,  0.7477,  0.4424,  0.7053,  7.5648,  1.0466,  1.8300,\n",
      "         0.3691,  5.0482,  0.3822,  1.7442, 13.9810,  4.0591,  4.0960,  0.3542,\n",
      "         3.0868,  0.6597,  1.2127,  6.4805,  3.8322,  0.4945,  1.0734,  2.5074,\n",
      "         0.3970,  1.8797,  0.6576,  9.9032,  3.4065,  0.5683,  0.4577,  0.8123,\n",
      "         0.7420,  0.5256,  5.5589,  0.6262,  5.7820,  1.8428, 16.1927,  0.5197,\n",
      "        17.2217,  9.7219,  0.9632,  4.9650,  0.5847,  0.3318,  2.1663,  8.6752,\n",
      "         3.4654,  2.2461,  0.5366,  1.8122,  0.2658,  0.6518, 14.7557,  3.5328,\n",
      "         7.3900,  2.1195,  2.5138,  5.2564,  3.3430,  7.9019,  1.2401,  0.3428,\n",
      "         1.2268, 14.1726,  2.1133,  9.7539,  6.6362, 12.6863,  0.3311,  2.0105,\n",
      "         1.3060,  1.5450,  2.4002,  5.9286,  0.6273,  6.6088,  2.0762,  2.3351,\n",
      "        12.2761,  4.8276,  1.6628,  0.5576,  2.3853,  0.8569,  0.4953,  6.4172,\n",
      "         5.2546,  7.3892, 14.5664,  1.6533,  2.0107,  0.4598,  0.8377,  2.4069,\n",
      "         3.3741, 13.2841,  2.4374,  1.8709,  1.7872, 10.4343,  2.1120,  1.7881,\n",
      "         3.5074,  1.5689, 13.0506,  1.4125,  1.1373,  4.5953,  1.6834,  1.2534,\n",
      "         2.1000,  1.9609,  6.2860,  2.0538,  2.6020,  2.4341,  3.3141,  2.4303,\n",
      "         5.8113])\n",
      "roi_bin_grid_h  2  roi_bin_grid_w  2\n"
     ]
    }
   ],
   "source": [
    "bin_size_h=roi_height/pooled_height # [K]\n",
    "bin_size_w=roi_width/pooled_width # [K]\n",
    "print('bin_size_h ', bin_size_h[:10], ' bin_size_w ', bin_size_w[:10])\n",
    "\n",
    "exact_sampling=sampling_ratio>0\n",
    "\n",
    "roi_bin_grid_h=sampling_ratio if exact_sampling else torch.ceil(roi_height/pooled_height) # scalar or [K]\n",
    "roi_bin_grid_w=sampling_ratio if exact_sampling else torch.ceil(roi_width/pooled_width) # scalar or [K]\n",
    "print('roi_bin_grid_h ', roi_bin_grid_h,  ' roi_bin_grid_w ', roi_bin_grid_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39fb951d-bc1a-4774-95f2-a1f4457282d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count  4  iy  torch.Size([2])  ix  torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "if exact_sampling:\n",
    "    count=max(roi_bin_grid_h*roi_bin_grid_w, 1) # scalar\n",
    "    iy=torch.arange(roi_bin_grid_h, device=input.device) # [IY]\n",
    "    ix=torch.arange(roi_bin_grid_w, device=input.device) # [IX]\n",
    "    ymask=xmask=None\n",
    "    print('count ', count, ' iy ', iy.shape, ' ix ', ix.shape)\n",
    "else:\n",
    "    count=torch.clamp(roi_bin_grid_h*roi_bin_grid_w, min=1) # [K]\n",
    "    # When doing adaptive sampling, the number of samples we need to do is data-dependent based on how big the ROIs are\n",
    "    # This is a bit awkward because first class dims cannot actually handle this. So instead, we inefficiently suppose that \n",
    "    # we needed to sample ALL the points and mask out things that turned out to be unnecessary\n",
    "    iy=torch.arange(height, device=input.device) #[IY]\n",
    "    ix=torch.arange(width, device=input.device) # [IX]\n",
    "    ymask=iy[None,:]<roi_bin_grid_h[:,None] # [K, IY]\n",
    "    xmask=ix[None,:]<roi_bin_grid_w[:, None] # [K, IX]\n",
    "\n",
    "def from_K(t): return t[:,None, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b3f8f77-b825-4616-8071-69d84f50ef93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from_K(roi_start_h)  torch.Size([849, 1, 1]) 0.0 199.1089630126953\n",
      "ph[None,:,None]*from(bin_size_h)  torch.Size([849, 7, 1]) 0.0 108.95317840576172\n",
      "(iy[None,None,:]+0.5).to(input.dtype)*from_K(bin_size_h/roi_bin_grid_h)  torch.Size([849, 1, 2]) 0.0357142873108387 13.619147300720215\n"
     ]
    }
   ],
   "source": [
    "tmp=from_K(roi_start_h)\n",
    "print('from_K(roi_start_h) ', tmp.shape, tmp.min().item(), tmp.max().item())\n",
    "tmp=ph[None,:,None]*from_K(bin_size_h)\n",
    "print('ph[None,:,None]*from(bin_size_h) ', tmp.shape, tmp.min().item(), tmp.max().item())\n",
    "tmp=(iy[None,None,:]+0.5).to(input.dtype)*from_K(bin_size_h/roi_bin_grid_h)\n",
    "print('(iy[None,None,:]+0.5).to(input.dtype)*from_K(bin_size_h/roi_bin_grid_h) ', tmp.shape, tmp.min().item(), tmp.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "940bb421-1012-4964-919e-c1c397f51397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y  torch.Size([849, 7, 2]) 0.08404339849948883 200.07325744628906\n",
      "x torch.Size([849, 7, 2]) 0.051833927631378174 286.4441223144531\n"
     ]
    }
   ],
   "source": [
    "#[K, PH, IY] = [K,1,1] + [K,PH,1] + [K,1,IY] note: sub-bin location was move to the center pixel\n",
    "y=from_K(roi_start_h) + ph[None,:,None]*from_K(bin_size_h) + (iy[None,None,:]+0.5)*from_K(bin_size_h/roi_bin_grid_h)\n",
    "print('y ', y.shape, y.min().item(), y.max().item())\n",
    "#[K, PW, IX] = [K,1,1] + [K,PW,1] + [K,1,IX] note: sub-bin location was move to the center pixel\n",
    "x=from_K(roi_start_w) + pw[None,:,None]*from_K(bin_size_w) + (ix[None,None,:]+0.5)*from_K(bin_size_w/roi_bin_grid_w)\n",
    "print('x', x.shape, x.min().item(), x.max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade3746-026b-44b0-8bdc-9d9beb016306",
   "metadata": {},
   "source": [
    "```\n",
    "val = _bilinear_interpolate(input, roi_batch_ind, y, x, ymask, xmask)  # [K, C, PH, PW, IY, IX]\n",
    "```\n",
    "[`_bilinear_interpolate`](https://github.com/pytorch/vision/blob/main/torchvision/ops/roi_align.py#L35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ecc0210-b0aa-42da-96b2-a6acaa52459d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y  torch.Size([849, 7, 2]) 0.08404339849948883 200.07325744628906\n",
      "x  torch.Size([849, 7, 2]) 0.051833927631378174 286.4441223144531\n",
      "y_low  torch.Size([849, 7, 2]) 0 200\n",
      "y_high  torch.Size([849, 7, 2]) 1 199\n",
      "y_low  torch.Size([849, 7, 2]) 0 199\n",
      "y  torch.Size([849, 7, 2]) 0.08404339849948883 200.07325744628906\n"
     ]
    }
   ],
   "source": [
    "_, channels, height, width=input.size()\n",
    "# deal with inverse element out of feature map boundary\n",
    "y=y.clamp(min=0)\n",
    "x=x.clamp(min=0)\n",
    "print('y ', y.shape, y.min().item(), y.max().item())\n",
    "print('x ', x.shape, x.min().item(), x.max().item())\n",
    "y_low=y.int()\n",
    "x_low=x.int()\n",
    "print('y_low ', y_low.shape, y_low.min().item(), y_low.max().item())\n",
    "y_high=torch.where(y_low>=height-1, height-1, y_low+1)\n",
    "y_low=torch.where(y_low>=height-1, height-1, y_low)\n",
    "print('y_high ', y_high.shape, y_high.min().item(), y_high.max().item())\n",
    "print('y_low ', y_low.shape, y_low.min().item(), y_low.max().item())\n",
    "y=torch.where(y_low>=height-1, y.to(input.dtype), y)\n",
    "print('y ', y.shape, y.min().item(), y.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92f56e20-d44a-43ef-abf1-101e9949bd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x  torch.Size([849, 7, 2]) 0.051833927631378174 286.4441223144531 torch.float32\n",
      "x_high  torch.Size([849, 7, 2]) 1 287 torch.int32\n",
      "x_low  torch.Size([849, 7, 2]) 0 286 torch.int32\n",
      "x  torch.Size([849, 7, 2]) 0.051833927631378174 286.4441223144531 torch.float32\n"
     ]
    }
   ],
   "source": [
    "print('x ', x.shape, x.min().item(), x.max().item(), x.dtype)\n",
    "x_high=torch.where(x_low>=width-1, width-1, x_low+1)\n",
    "x_low=torch.where(x_low>=width-1, width-1, x_low)\n",
    "print('x_high ', x_high.shape, x_high.min().item(), x_high.max().item(), x_high.dtype)\n",
    "print('x_low ', x_low.shape, x_low.min().item(), x_low.max().item(), x_low.dtype)\n",
    "x=torch.where(x_low>=width-1, x.to(input.dtype), x)\n",
    "print('x ', x.shape, x.min().item(), x.max().item(), x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6487be6b-6158-4a44-9066-b6b67637c5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ly  torch.Size([849, 7, 2]) 4.57763671875e-05 1.0732574462890625\n",
      "lx  torch.Size([849, 7, 2]) 6.103515625e-05 0.999969482421875\n",
      "hy  torch.Size([849, 7, 2]) -0.0732574462890625 0.9999542236328125\n",
      "hx  torch.Size([849, 7, 2]) 3.0517578125e-05 0.99993896484375\n"
     ]
    }
   ],
   "source": [
    "ly=y-y_low\n",
    "lx=x-x_low\n",
    "hy=1.-ly\n",
    "hx=1.-lx\n",
    "print('ly ', ly.shape, ly.min().item(), ly.max().item())\n",
    "print('lx ', lx.shape, lx.min().item(), lx.max().item())\n",
    "print('hy ', hy.shape, hy.min().item(), hy.max().item())\n",
    "print('hx ', hx.shape, hx.min().item(), hx.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c4258da-a060-4ac1-9eb7-2efcd7387ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input  torch.Size([2, 256, 200, 296])\n",
      "roi_batch_ind[:, None, None, None, None, None]  torch.Size([849, 1, 1, 1, 1, 1])\n",
      "C  torch.Size([1, 256, 1, 1, 1, 1])\n",
      "y[:, None, :, None, :, None],  # prev [K, PH, IY]  torch.Size([849, 1, 7, 1, 2, 1])\n",
      "x[:, None, None, :, None, :],  # prev [K, PW, IX]  torch.Size([849, 1, 1, 7, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "print('input ', input.shape)\n",
    "print('roi_batch_ind[:, None, None, None, None, None] ', roi_batch_ind[:, None, None, None, None, None].shape)\n",
    "C=torch.arange(channels, device=input.device)[None, :, None, None, None, None]\n",
    "print('C ', C.shape)\n",
    "print('y[:, None, :, None, :, None],  # prev [K, PH, IY] ',\n",
    "     y[:, None, :, None, :, None].shape)\n",
    "print('x[:, None, None, :, None, :],  # prev [K, PW, IX] ',\n",
    "     x[:, None, None, :, None, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41dd7931-dc13-47e6-b51d-0f213ef12bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_index(\n",
    "    y, #[K, PH, IY]\n",
    "    x, #[K, PW, IX]\n",
    "):\n",
    "    if ymask is not None:\n",
    "        assert xmask is not None\n",
    "        y=torch.where(ymask[:, None], y, 0)\n",
    "        x=torch.where(xmask[:,None], x, 0)\n",
    "    return input[roi_batch_ind[:,None, None, None,None,None],\n",
    "    torch.arange(channels, device=input.device)[None,:,None,None,None,None],\n",
    "    y[:,None,:,None,:,None], # prev [K, PH, IY]\n",
    "    x[:,None,None,:,None,:], # prev [K, PW, IX]\n",
    "    ] # [K, C, PH, PW, IY, IX]\n",
    "\n",
    "v1=masked_index(y_low, x_low)\n",
    "v2=masked_index(y_low, x_high)\n",
    "v3=masked_index(y_high, x_low)\n",
    "v4=masked_index(y_high, x_high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0af07023-f4fc-4557-944d-e55f37e66deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val  torch.Size([849, 256, 7, 7, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "from torchvision.ops.roi_align import _bilinear_interpolate\n",
    "\n",
    "val = _bilinear_interpolate(input, roi_batch_ind, y, x, ymask, xmask)  # [K, C, PH, PW, IY, IX]\n",
    "print('val ', val.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:op_cv]",
   "language": "python",
   "name": "conda-env-op_cv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
