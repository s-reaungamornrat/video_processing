{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9e318b9-49e5-4e1c-a125-66c80b2b30ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from matching import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d13efb78-ba88-4e83-8591-0d758f8d4cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_boxes  [torch.Size([2, 4]), torch.Size([5, 4])]\n",
      "gt_labels  [torch.Size([2]), torch.Size([5])]\n",
      "proposals  [torch.Size([217415, 4]), torch.Size([217418, 4])]\n"
     ]
    }
   ],
   "source": [
    "data_dirpath='D:/data/mask_rcnn'\n",
    "fg_iou_thresh=0.5\n",
    "bg_iou_thresh=0.5\n",
    "\n",
    "device=torch.device(\"cpu\")\n",
    "roi_head_assign_targets_to_proposal=torch.load(os.path.join(data_dirpath, \"roi_head_assign_targets_to_proposal.pt\"),map_location=device, weights_only=True)\n",
    "gt_boxes=roi_head_assign_targets_to_proposal['gt_boxes']\n",
    "gt_labels=roi_head_assign_targets_to_proposal['gt_labels']\n",
    "proposals=roi_head_assign_targets_to_proposal['proposals']\n",
    "print('gt_boxes ', [g.shape for g in gt_boxes])\n",
    "print('gt_labels ', [g.shape for g in gt_labels])\n",
    "print('proposals ', [p.shape for p in proposals])\n",
    "\n",
    "proposal_matcher = Matcher(fg_iou_thresh, bg_iou_thresh, allow_low_quality_matches=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "825762bd-9936-4a12-b08e-9229ee63ab50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_boxes_in_image  torch.Size([2, 4])\n",
      "proposals_in_image  torch.Size([217415, 4])\n",
      "gt_boxes_in_image  torch.Size([5, 4])\n",
      "proposals_in_image  torch.Size([217418, 4])\n",
      "\n",
      "matched_idxs  [(torch.Size([217415]), tensor(0), tensor(1)), (torch.Size([217418]), tensor(0), tensor(4))]\n",
      "labels  [(torch.Size([217415]), tensor(0), tensor(1)), (torch.Size([217418]), tensor(0), tensor(1))]\n"
     ]
    }
   ],
   "source": [
    "matched_idxs, labels=[],[]\n",
    "\n",
    "for proposals_in_image, gt_boxes_in_image, gt_labels_in_image in zip(proposals, gt_boxes, gt_labels):\n",
    "    print('gt_boxes_in_image ', gt_boxes_in_image.shape)\n",
    "    print('proposals_in_image ', proposals_in_image.shape)\n",
    "    if gt_boxes_in_image.numel()==0:\n",
    "        # background image\n",
    "        device=proposals_in_image.device\n",
    "        clamped_matched_idxs_in_image=torch.zeros((proposals_in_image.shape[0],), dtype=torch.int64,\n",
    "                                                 device=device)\n",
    "        labels_in_image=torch.zeros((proposals_in_image.shape[0],), dtype=torch.int64, device=device)\n",
    "    else:\n",
    "        # MxN from Mx4 and Nx4\n",
    "        match_quality_matrix=torchvision.ops.box_iou(gt_boxes_in_image,proposals_in_image) \n",
    "        matched_idxs_in_image=proposal_matcher(match_quality_matrix) # N\n",
    "\n",
    "        clamped_matched_idxs_in_image=matched_idxs_in_image.clamp(min=0)\n",
    "\n",
    "        labels_in_image=gt_labels_in_image[clamped_matched_idxs_in_image]\n",
    "        labels_in_image=labels_in_image.to(dtype=torch.int64)\n",
    "\n",
    "        # label background (below the low threshold)\n",
    "        bg_inds=matched_idxs_in_image==proposal_matcher.BELOW_LOW_THRESHOLD\n",
    "        labels_in_image[bg_inds]=0\n",
    "\n",
    "        # Label ignore proposals (between low and high thresholds)\n",
    "        ignore_inds=matched_idxs_in_image==proposal_matcher.BETWEEN_THRESHOLDS\n",
    "        labels_in_image[ignore_inds]=-1 # -1 is ignored by sampler\n",
    "        \n",
    "    matched_idxs.append(clamped_matched_idxs_in_image)\n",
    "    labels.append(labels_in_image)\n",
    "\n",
    "print('\\nmatched_idxs ', [(m.shape,m.min(), m.max()) for m in matched_idxs])\n",
    "print('labels ', [(l.shape, l.min(), l.max()) for l in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579e8968-e5be-4412-af8f-0189799ca8b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "op_cv",
   "language": "python",
   "name": "op_cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
